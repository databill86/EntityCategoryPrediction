{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_word(word_length):\n",
    "    word_len = np.random.randint(*word_length)\n",
    "    return ''.join(random.sample(string.ascii_lowercase, word_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_size = 6\n",
    "num_topics = 20\n",
    "\n",
    "topics = [\n",
    "    [gen_word((2,6)) for _ in range(topic_size)] for _ in range(num_topics)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ikm', 'bxorj', 'kz', 'pw', 'vryts', 'qza'],\n",
       " ['pckid', 'xym', 'lhipy', 'ot', 'hz', 'rdv'],\n",
       " ['ip', 'zegrw', 'abs', 'oe', 'cyvb', 'ick'],\n",
       " ['yshl', 'jc', 'pdbl', 'tuh', 'ibfp', 'bz'],\n",
       " ['ysior', 'de', 'szlo', 'yn', 'gxc', 'wihz'],\n",
       " ['kspq', 'hj', 'dthmj', 'lmjvw', 'hay', 'yel'],\n",
       " ['fmbsc', 'azvh', 'pb', 'vrns', 'ibs', 'eab'],\n",
       " ['xze', 'xbfqy', 'ptems', 'dwz', 'hnfp', 'usa'],\n",
       " ['bdx', 'zb', 'ga', 'she', 'se', 'vw'],\n",
       " ['cqg', 'ysjeb', 'jnofp', 'hmtu', 'dop', 'eq'],\n",
       " ['vons', 'ilckw', 'kzedo', 'hlzb', 'rjb', 'tue'],\n",
       " ['fbx', 'dweup', 'qs', 'va', 'wyu', 'jvnrd'],\n",
       " ['bn', 'dfvs', 'vr', 'ax', 'vkb', 'kaqly'],\n",
       " ['ics', 'qlcw', 'lfvdi', 'ox', 'nw', 'qml'],\n",
       " ['anbit', 'xqiy', 'fspyj', 'wmqnh', 'awlt', 'fvb'],\n",
       " ['sy', 'lmwz', 'zgu', 'ksieq', 'tvwqx', 'dpfi'],\n",
       " ['czqbf', 'wvo', 'hq', 'lmowd', 'ufb', 'izc'],\n",
       " ['mtuqg', 'gbhc', 'uh', 'ye', 'uhpg', 'eycs'],\n",
       " ['mskrg', 'rmvzo', 'rljbq', 'tdjvo', 'xfs', 'wdgkm'],\n",
       " ['utlio', 'bp', 'roct', 'ivuf', 'iral', 'bt']]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(m_topics):\n",
    "    sent = []\n",
    "    prefix_topics = 1\n",
    "    suffix_topics = 1\n",
    "    \n",
    "    for i in range(prefix_topics):\n",
    "        sent += random.sample(topics[random.choice(range(num_topics))], random.randint(0,2))\n",
    "        \n",
    "    sent += random.sample(topics[random.choice(m_topics)], random.randint(0,2)) + ['M'] + random.sample(topics[random.choice(m_topics)], random.randint(0,2))\n",
    "    \n",
    "    for i in range(suffix_topics):\n",
    "        sent += random.sample(topics[random.choice(range(num_topics))], random.randint(0,2))\n",
    "      \n",
    "    return sent\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([5, 7], ['mskrg', 'wdgkm', 'ptems', 'M', 'kspq', 'yel', 'qza', 'bxorj'])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_topics = random.choices(range(num_topics), k=2)\n",
    "m_topics, generate_sentence(m_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_to_file(file_path, count=1000):\n",
    "    with open(file_path, 'w') as out:\n",
    "        for i in range(count):\n",
    "            m_topics = random.choices(range(num_topics), k=2)\n",
    "            topics_str = \"_\".join(map(str, m_topics))\n",
    "            for j in range(random.randint(2, 4)):\n",
    "                sent = generate_sentence(m_topics)\n",
    "                out.write(' '.join(sent) + \"\\t\" + topics_str + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_to_file('../data/fake_data_train.tsv')\n",
    "generate_to_file('../data/fake_data_valid.tsv', count=500)          \n",
    "generate_to_file('../data/fake_data_test.tsv', count=500) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/fake_ft_data.tsv', 'w') as out:\n",
    "    for i in range(1000):\n",
    "        m_topics = random.choices(range(num_topics), k=2)\n",
    "        topics_str = \"_\".join(map(str, m_topics))\n",
    "        for j in range(random.randint(2, 4)):\n",
    "            sent = generate_sentence(m_topics)\n",
    "            out.write(' '.join(sent) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install git+https://github.com/facebookresearch/fastText.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fastText.train_unsupervised(\n",
    "    input='../data/fake_ft_data.tsv', minCount=0, bucket=1000, dim=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.get_words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(\"../data/fake_ft_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "from gensim.models.utils_any2vec import ft_ngram_hashes\n",
    "from gensim.models.utils_any2vec import compute_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = FastText.load_fasttext_format(\"../data/fake_ft_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft.save('../data/gensim_fake_ft.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft2 = FastText.load('../data/gensim_fake_ft.model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
