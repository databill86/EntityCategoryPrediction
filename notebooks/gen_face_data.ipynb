{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_word(word_length):\n",
    "    word_len = np.random.randint(*word_length)\n",
    "    return ''.join(random.sample(string.ascii_lowercase, word_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_size = 6\n",
    "num_topics = 20\n",
    "\n",
    "topics = [\n",
    "    [gen_word((2,6)) for _ in range(topic_size)] for _ in range(num_topics)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['atipl', 'uy', 'ehby', 'hs', 'tclv', 'qifph'],\n",
       " ['xzmtq', 'cg', 'nv', 'wc', 'nj', 'reh'],\n",
       " ['dfv', 'cgu', 'mhp', 'rfu', 'myeka', 'kxm'],\n",
       " ['wovgr', 'rez', 'kiw', 'kjan', 'xcklr', 'hf'],\n",
       " ['btzoj', 'viqjy', 'gfkr', 'puwvs', 'bqvl', 'dt'],\n",
       " ['ivkjl', 'rln', 'xfhvu', 'ot', 'pctl', 'tqn'],\n",
       " ['jmw', 'dfai', 'nzrjo', 'hatue', 'ljzae', 'my'],\n",
       " ['esrpk', 'oe', 'edih', 'eosi', 'dywu', 'mun'],\n",
       " ['yf', 'wzrd', 'sqek', 'jpe', 'uia', 'soq'],\n",
       " ['jpvs', 'gyvdp', 'nlry', 'xzb', 'vk', 'cb'],\n",
       " ['mctf', 'sahzm', 'vqxh', 'bcal', 'detw', 'brace'],\n",
       " ['dxmg', 'jdfe', 'ohm', 'yg', 'wi', 'yshdp'],\n",
       " ['fnx', 'kxhen', 'sd', 'jf', 'opk', 'knel'],\n",
       " ['elh', 'gvt', 'nc', 'pw', 'onuij', 'ak'],\n",
       " ['ynrqm', 'jx', 'qsw', 'vonet', 'ku', 'upib'],\n",
       " ['mpey', 'jpzdy', 'ji', 'nwjk', 'ops', 'pneuc'],\n",
       " ['khgpj', 'ns', 'tzo', 'wnrf', 'mqs', 'vgbwe'],\n",
       " ['apg', 'leu', 'ki', 'tvk', 'yazcx', 'fkiqe'],\n",
       " ['pwzgc', 'hewa', 'szg', 'eyn', 'skd', 'bs'],\n",
       " ['guv', 'dnbe', 'ipc', 'kdf', 'ikbsh', 'hmy']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(m_topics):\n",
    "    sent = []\n",
    "    prefix_topics = 1\n",
    "    suffix_topics = 1\n",
    "    \n",
    "    for i in range(prefix_topics):\n",
    "        sent += random.sample(topics[random.choice(range(num_topics))], random.randint(0,2))\n",
    "        \n",
    "    sent += random.sample(topics[random.choice(m_topics)], random.randint(0,2)) + ['M'] + random.sample(topics[random.choice(m_topics)], random.randint(0,2))\n",
    "    \n",
    "    for i in range(suffix_topics):\n",
    "        sent += random.sample(topics[random.choice(range(num_topics))], random.randint(0,2))\n",
    "      \n",
    "    return sent\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([14, 6], ['M', 'dfai', 'jmw', 'yg', 'yshdp'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_topics = random.choices(range(num_topics), k=2)\n",
    "m_topics, generate_sentence(m_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/fake_data.tsv', 'w') as out:\n",
    "    for i in range(1000):\n",
    "        m_topics = random.choices(range(num_topics), k=2)\n",
    "        topics_str = \"_\".join(map(str, m_topics))\n",
    "        for j in range(random.randint(2, 4)):\n",
    "            sent = generate_sentence(m_topics)\n",
    "            out.write(' '.join(sent) + \"\\t\" + topics_str + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/fake_ft_data.tsv', 'w') as out:\n",
    "    for i in range(1000):\n",
    "        m_topics = random.choices(range(num_topics), k=2)\n",
    "        topics_str = \"_\".join(map(str, m_topics))\n",
    "        for j in range(random.randint(2, 4)):\n",
    "            sent = generate_sentence(m_topics)\n",
    "            out.write(' '.join(sent) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install git+https://github.com/facebookresearch/fastText.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fastText.train_unsupervised(\n",
    "    input='../data/fake_ft_data.tsv', minCount=0, bucket=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.get_words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['<bp',\n",
       "  '<bpx',\n",
       "  '<bpxr',\n",
       "  '<bpxre',\n",
       "  'bpx',\n",
       "  'bpxr',\n",
       "  'bpxre',\n",
       "  'bpxre>',\n",
       "  'pxr',\n",
       "  'pxre',\n",
       "  'pxre>',\n",
       "  'xre',\n",
       "  'xre>',\n",
       "  're>'],\n",
       " array([ 963, 1117,  165,  196,  367,  815,  962,  676,  599,  842,  988,\n",
       "         728,  658,  620]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_subwords('bpxre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(\"../data/fake_ft_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "from gensim.models.utils_any2vec import ft_ngram_hashes\n",
    "from gensim.models.utils_any2vec import compute_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = FastText.load_fasttext_format(\"../data/fake_ft_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft.save('../data/gensim_fake_ft.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft2 = FastText.load('../data/gensim_fake_ft.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"minn\": ft2.wv.min_n,\n",
    "    \"maxn\": ft2.wv.max_n,\n",
    "    \"num_buckets\": ft2.wv.bucket,\n",
    "    \"fb_compatible\": ft2.wv.compatible_hash\n",
    "}\n",
    "\n",
    "vocab = dict((word, keydvector.index) for word, keydvector in ft2.wv.vocab.items())\n",
    "hash2index = ft2.wv.hash2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ids(word):\n",
    "    \n",
    "    if word in vocab:\n",
    "        return np.array([vocab[word]])\n",
    "    res = []\n",
    "    for ngram_id in ft_ngram_hashes(word, **params):\n",
    "        res.append(hash2index.get(ngram_id, ngram_id) + len(ft2.wv.vocab))\n",
    "        \n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([87])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ids('brace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1122, 100)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([ft2.wv.vectors_vocab, ft2.wv.vectors_ngrams], axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122, 100)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft2.wv.vectors_vocab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1122"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft2.wv.vectors_vocab.shape[0] + ft2.wv.vectors_ngrams.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
